I"($<p>After graduating from the UBC Master of Data Science program for close to a year, I decided to do some reflections on my personal experience so far. For all readers, I hope you may find this relatable in your journey/experience so far.</p>

<h1 id="1-all-models-are-wrong-but-some-are-useful">1. All models are wrong but some are useful</h1>

<p>This quote by George Box has been resurfacing in my thoughts over the past year as I grappled around the idea of causality in the space of machine learning (ML).</p>

<p>While doing self-learning on <a href="https://www.bradyneal.com/causal-inference-course">Brady Neal’s Causal Inference course</a>, there was a guest talk by <a href="https://youtu.be/rKZJ0TJWvTk?t=167">Yoshua Bengio on the topic of “Towards Causal Representation Learning”</a> where he describe the philosophical concept of “representation”. In his talk, he mentioned how a physicist might want to capture a causal model by measuring the information flow at a physical level of atoms and the forces of nature, but for other applications of causal thinking, we do not need to model at such microsecond scales. In fact, we want to model a causal structure that is made up of “abstractions” or some form of artificial aggregated constructs that are meant to have an inherent logical representation.</p>

<p>Thus, even when we talk about creating models, there is nothing that can validate that your proposed model of a linear regression is “universally” correct. What we are doing is actually using aggregated “abstractions” to help us understand the world, but all of that are just constructs made by us.</p>

<p>Although it might sound disheartening to know that there is no true model, it’s actually not the end of the world. One can still use these models to provide immense value. In <a href="https://youtu.be/zwcjJQoK8_Q?list=WL&amp;t=3524">David Blei’s talk on “Economics and Probabilistic Machine Learning”</a>, a question posed to him during Q&amp;A was about the concept of a “true” model. David talked about the concept of model misspecification, and brought up his idea of text topic modelling using Poisson matrix factorisation. In his words, he states the following:</p>

<p>“…I don’t think there’s a true model. I think these models are all simplications, and they’re for a purpose…I’ve done a lot of work in topic modelling with John, and we don’t believe that text comes from a topic model. That would be insane to believe that. But rather, that particular characterisation of the hidden variables in text is useful for building navigators based on themes that help someone quickly explore a massive dataset. So personally, I’m not sure there’s a true model…”</p>

<p>I thought that was very enlightening, and helped to provide some form of existential guardrail that prevented me from succumbing to the idea that every model we create is futile or pointless.</p>

<h1 id="2-garbage-in-garbage-out">2. Garbage in, garbage out</h1>

<p>Most of the data science syllabus are framed in a way to teach you how to apply various predictive algorithms to various data. A large part of my learning experience on the Internet is centered around following package vignettes or walkthrough tutorials that utilise publicly available datasets that have been curated/approved, which promotes the learning concepts in a controlled envinronment.</p>

<p>Based on my personal experience over the past year, useful data is not always available and you have to spend time thinking about procuring them. Depending on circumstances, your organisation may still be in a nascent stage where it has not established the right infrastructure. Just parsing through the e-book <a href="https://experimentguide.com/">“Trustworthy Online Controlled Experiments : A Practical Guide to A/B Testing”</a> taught me that it is absolutely critical to set up the right infrastructure for collecting high quality instrumentation data so that you can trust the results of any experiments.</p>

<p>Although data science has been hyped up by the “shiny” promise of machine learning technology buzzwords, the actual “value” of data science applications is affected by a lot of factors, one of which is the availability (or lack) of useful data. What I realised is to be effective as a data scientist, beyond learning the different ML algorithms, one needs to learn the critical technical skills so he/she can:</p>
<ul>
  <li>navigate the organisational infrastructure to access the right data if it currently exists</li>
  <li>propose changes to the infrastructure so that the right data can be collected if it does not exist</li>
  <li>ensure that the data transformation/preprocessing workflow is appropriate</li>
</ul>

<p>On a similar note, this brings me to the next point about the implicit assumptions when using ML for modelling.</p>

<h1 id="3-inappropriate-assumptions-with-ml-applications">3. (In)appropriate assumptions with ML applications</h1>

<p>Most of the data science algorithms are meant to deal with situations where the data is stationary. If the data distribution is stationary and the independent and identically distributed (iid), then various ML algorithms can be applied to provide the necessary inference or predictions alogn with other rules of thumb to ensure performance generalisation such as cross-validation methodology for hyperparameter tuning.</p>

<p>Just thinking about my past experience as a chemical engineer, I used to deal with thermodynamics and equations that were considered “laws”. Behind this mindset or thinking came with a huge set of assumptions: the observations collected (whether be it a temperature reading or pressure reading) came from an underlying universal data-generating process that followed some “natural” phenomenon, and it was up to me as an engineer to provide solutions such as yield optimisation or even human safety by analysing the data collected.</p>

<p>However, data science has been applied on a lot of various fields where the data distributions are highly not invariant. Think about data science applications centered around human behaviour. In our society, there has always been a constant shift/evolution in the aggregate consciousness be it on a global level or a local/regional level. What was trendy previously 5 years ago may no longer be fashionable, and this has implications on recommenders system used in e-commerce platforms.</p>

<p>When it comes to globalisation, we see a confluence mix of cultures which can simultaneously erode existing languages or result in the emergence of novel lingo (“yeet”!). Assuming there is indeed an underlying true data generating process that can be modelled (See Point 1), this means that there is constant covariate shift which is actually up to the data scientist to identify and resolve. This is actually an extremely difficult task in my opinion, and I would love to find out more on how to deal with it.</p>

<p>I also want to point out that there are certain applications where the dataset is curated but yet assumed to come from some form of “natural” distribution before applying ML statistical modelling for prediction. For example, one may scrape various images from the internet to do a classification task. If you think more about it in detail, there is nothing “natural” in those images. Those images are generated from someone who decided to choose to capture a photo of a particular object (perhaps in a certain angle or lighting or special occasion). There is an inherent selection bias in terms of the data generated, and to simply use ML algorithms (with the assumption that the data is iid) is actually at best inappropriate or for lack of better words, wrong. For an indepth reference, see this talk <a href="https://youtu.be/yFXPU2lMNdk?t=446">“Learning Representation Using Causal Invariance” by Leon Bottou</a>. Below shows a particular slide from his talk which surmises the above point. His slides can be found <a href="https://leon.bottou.org/slides/invariances/invariances.pdf">here</a></p>

<p align="center">
    <img src="/assets/img/post_14/leon_bottou_slide.png" /> 
</p>

<h1 id="think-hard-about-what-youre-doing">Think hard about what you’re doing</h1>

<p>In my opinion, one can be more conscious of the possible blindspots that may be prevalent in a data science related role. By applying more deliberate critical thinking and logic, one can acknowledge the actual potential and limitations of the “supposed” value that a data scientist can contribute to your organisation. Building off that, that’s why I think organisations with a diverse team actually help to anchor, correct and manage the expectations of various (internal or external) stakeholders regarding the value of data science.</p>

<p>If you have made it this far, thanks for reading! I hope that you found this post relatable based on your experience, and that his post might have raise some awareness on the implications of using data science or ML modelling if you ever find yourself in a position to do so. Beyond that, I would love to hear more about anybody’s experience or insights about it so feel free to leave a comment!</p>
:ET